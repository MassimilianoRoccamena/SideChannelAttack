base:

  origin:
    - sca
    - profiling
    - classification

  name: KeyClassifierTemp #KeyClassifier0

  description: 'fit trace to key classifier'

# ---------------------------------------------------------------

determinism:

  seed: 314159
  seed_workers: True
  force: False

# ---------------------------------------------------------------

core:

  name: DeepClassification
  params:

# ---------------------------------------------------------------

dataset:
  skip:
    train: False
    test: False

  name: HammingSboxClassification
  params:
    loader:
      name: FileConvention2
      params:

    voltages:
      - '1.00'
    frequencies:
      - '45.000'
      #- '46.875'
      #- '48.000'
      #- '50.000'
      #- '50.125'
      #- '52.000'
      #- '54.000'
      #- '55.000'
      #- '56.000'
    key_values:
      #- '00'
      #- '01'
    plain_bounds: [0, 100]
    sets:
      - name: train
        size: 0.75
      - name: valid
        size: 0.15
      - name: test
        size: 0.1

    channels_first: True

model:
  checkpoint:

  name: SingleBasic
  params:
    encoder:
      name: VGG
      params:
        encoding_size: 600
        base_filters: 64
        conv_kernel_size: 20
        conv_stride: 2
        pool_kernel_size: 2
        use_batch_norm: True
        num_convs1: 2
        num_convs2: 3
        num_layers1: 2
        num_layers2: 3
        use_final_do: True
        final_do_val: 0.4

      #name: ResNet
      #params:
      #  encoding_size: 800
      #  base_filters: 27
      #  kernel_size: 20
      #  stride: 2
      #  groups: 1
      #  n_block: 4
      #  downsample_gap: 2
      #  increasefilter_gap: 2
      #  use_batch_norm: True
      #  use_inner_do: True
      #  inner_do_val: 0.4
      #  use_final_do: True
      #  final_do_val: 0.4

      #name: LSTM1
      #params:
      #  batch_first: True
      #  encoding_size: 50
      #  use_final_do: False
      #  final_do_val: 0.3
      #  hidden_size: 20
      #  num_layers: 7
        #dropout: 0.3
        #bidirectional: True

      #name: GRU1
      #params:
      #  batch_first: True
      #  encoding_size: 90
      #  use_final_do: True
      #  final_do_val: 0.1
      #  hidden_size: 300
      #  num_layers: 1
      #  dropout: 0.1
      #  bidirectional: True

      #name: Transformer
      #params:
      #  batch_first: True
      #  encoding_size: 160
      #  use_final_do: True
      #  final_do_val: 0.2
      #  dim_feedforward: 500
      #  nhead: 1
      #  dropout: 0.1

    #layers: [600, 100]
  

# ---------------------------------------------------------------

learning:

  loss:
    name: CrossEntropyLoss
    params:
      weight:
        - 12.0
        - 1.8
        - 0.514
        - 0.256
        - 0.2
        - 0.256
        - 0.514
        - 1.8
        - 12.0

  early_stopping:
    monitor: valid/loss
    patience: 7
    mode: min

  optimizer:
    name: SGD
    params:
      lr: 0.01
      momentum: 0.9
      weight_decay: 1e-4
    #name: Adam
    #params:
    #  lr: 0.0003

  scheduler:
    name: StepLR
    params:
      step_size: 1
      gamma: 0.9

  data_loader:
    batch_size: 32 #24
    shuffle: True
    num_workers: 4
    pin_memory: True

  trainer:
    gpus: 1
    max_epochs: 70
    check_val_every_n_epoch: 1
    log_every_n_steps: 2
    limit_train_batches: 0.2
    limit_val_batches: 0.3
    track_grad_norm: 2

  loggables:
    - name: Accuracy
      sets:
      params:
        average: weighted #macro

    - name: Precision
      sets:
      params:
        average: weighted #macro

    - name: Recall
      sets:
      params:
        average: weighted #macro
    
    - name: F1
      sets:
      params:
        average: weighted #macro

    - name: ConfusionMatrix
      sets:
      params:
    #    normalize: 'true'
    #    xticklabels: 20
    #    yticklabels: 20

    #- name: Inference
    #  sets:
    #    - 'test'
    #  params:
    #    log_encoding: True

# ---------------------------------------------------------------

logging:

  tensorboard:
    enable: True

  neptune:
    enable: TRUE
    
    log_model_checkpoints: False
    tags:
      - plain-0-100
      - vgg
      - sgd
      - freq-45.000
      - weighted-loss
      - log-fixed

    # source_files:
    # - '*.py'
    # - '*.sh'

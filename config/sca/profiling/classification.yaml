base:

  origin:
    - sca
    - profiling
    - classification

  name: KeyClassifier0

  description: 'fit trace to key classifier'

# ---------------------------------------------------------------

determinism:

  seed: 314159
  seed_workers: True
  force: False

# ---------------------------------------------------------------

core:

  name: DeepClassification
  params:

# ---------------------------------------------------------------

dataset:
  skip:
    train: False
    test: False

  name: HammingKeyClassification
  params:
    loader:
      name: FileConvention2
      params:

    voltages:
      - '1.00'
    frequencies:
      - '45.000'
      - '46.875'
      - '48.000'
      - '50.000'
      - '50.125'
      - '52.000'
      - '54.000'
      - '55.000'
      - '56.000'
    key_values:
      #- '00'
      #- '01'
    plain_bounds: [0, 50]
    sets:
      - name: train
        size: 0.75
      - name: valid
        size: 0.15
      - name: test
        size: 0.1

    channels_first: True

model:
  checkpoint:

  name: SingleBasic
  params:
    encoder:
      name: ResNet
      params:
        encoding_size: 90
        base_filters: 18
        kernel_size: 200
        stride: 20
        groups: 1
        n_block: 8
        downsample_gap: 2
        increasefilter_gap: 4
        use_batch_norm: True
        use_inner_do: True
        inner_do_val: 0.5
        use_final_do: True
        final_do_val: 0.5

      #name: LSTM1
      #params:
      #  batch_first: True
      #  encoding_size: 90
      #  use_final_do: True
      #  final_do_val: 0.1
      #  hidden_size: 300
      #  num_layers: 1
      #  dropout: 0.1
      #  bidirectional: True

      #name: GRU1
      #params:
      #  batch_first: True
      #  encoding_size: 90
      #  use_final_do: True
      #  final_do_val: 0.1
      #  hidden_size: 300
      #  num_layers: 1
      #  dropout: 0.1
      #  bidirectional: True

      #name: Transformer
      #params:
      #  batch_first: True
      #  encoding_size: 160
      #  use_final_do: True
      #  final_do_val: 0.2
      #  dim_feedforward: 500
      #  nhead: 1
      #  dropout: 0.1

# ---------------------------------------------------------------

learning:

  loss:
    name: CrossEntropyLoss
    params:
      #weight:
      #  - 1.0
      #  - 3.0
      #  - 1.0
      #  - 3.0
      #  - 1.0
      #  - 1.0
      #  - 1.0
      #  - 1.0

  early_stopping:
    monitor: valid/loss
    patience: 7
    mode: min

  optimizer:
    name: SGD
    params:
      lr: 0.01
      momentum: 0.9
      weight_decay: 1e-4
    #name: Adam
    #params:
    #  lr: 0.00001

  scheduler:
    name: StepLR
    params:
      step_size: 2
      gamma: 0.9

  data_loader:
    batch_size: 32
    shuffle: True
    num_workers: 4
    pin_memory: True

  trainer:
    gpus: 1
    max_epochs: 100
    check_val_every_n_epoch: 1
    log_every_n_steps: 64
    limit_train_batches: 0.1
    limit_val_batches: 0.1
    track_grad_norm: 2

  loggables:
    - name: Accuracy
      sets:
      params:
        #average: samples

    - name: Precision
      sets:
      params:
        #average: samples

    - name: Recall
      sets:
      params:
        #average: samples
    
    - name: F1
      sets:
      params:
        #average: samples

    - name: ConfusionMatrix
      sets:
      params:
        normalize: 'true'
        xticklabels: 20
        yticklabels: 20

    - name: Inference
      sets:
        - 'test'
      params:
        log_encoding: True

# ---------------------------------------------------------------

logging:

  tensorboard:
    enable: True

  neptune:
    enable: True
    
    log_model_checkpoints: False
    tags:
      - plain-0-100
      - resnet
      - sgd

    # source_files:
    # - '*.py'
    # - '*.sh'

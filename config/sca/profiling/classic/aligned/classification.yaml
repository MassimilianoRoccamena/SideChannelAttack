base:

  origin:
    - sca
    - profiling
    - classic
    - aligned
    - classification

  name: A-FrequencyAligner
  id: 0

  description: 'fit window to frequency classifier, for trace alignment'

# ---------------------------------------------------------------

determinism:

  seed: 314159
  seed_workers: True
  force: False

# ---------------------------------------------------------------

core:

  name: DeepClassification
  params:

# ---------------------------------------------------------------

dataset:
  skip:
    train: False
    test: False #False

  name: FrequencyClassification
  params:
    loader:
      name: FileConvention2
      params:

    lookup_path: /data/output/A-WindowLookup/0
    channels_first: True

model:
  checkpoint:

  name: SingleBasic
  params:
    encoder:
      #name: VGG
      #params:
      #  encoding_size: 180
      #  base_filters: 64
      #  conv_kernel_size: 20
      #  conv_stride: 2
      #  pool_kernel_size: 2
      #  use_batch_norm: True
      #  num_convs1: 2
      #  num_convs2: 2
      #  num_layers1: 3
      #  num_layers2: 3
      #  use_final_do: True
      #  final_do_val: 0.4

      name: ResNet
      params:
        encoding_size: 50
        base_filters: 18
        kernel_size: 20
        stride: 2
        groups: 1
        n_block: 6
        downsample_gap: 2
        increasefilter_gap: 2
        use_batch_norm: True
        use_inner_do: False
        inner_do_val: 0.
        use_final_do: True
        final_do_val: 0.2

      #name: LSTM1
      #params:
      #  batch_first: True
      #  encoding_size: 300
      #  use_final_do: True
      #  final_do_val: 0.4
      #  hidden_size: 100
      #  num_layers: 1
      #  dropout: 0.2
      #  bidirectional: True

      #name: GRU1
      #params:
      #  batch_first: True
      #  encoding_size: 90
      #  use_final_do: True
      #  final_do_val: 0.1
      #  hidden_size: 300
      #  num_layers: 1
      #  dropout: 0.1
      #  bidirectional: True

      #name: Transformer
      #params:
      #  batch_first: True
      #  encoding_size: 160
      #  use_final_do: True
      #  final_do_val: 0.2
      #  dim_feedforward: 500
      #  nhead: 1
      #  dropout: 0.1

# ---------------------------------------------------------------

learning:

  loss:
    name: CrossEntropyLoss
    params:
      #weight:
      #  - 1.0
      #  - 3.0
      #  - 1.0
      #  - 3.0
      #  - 1.0
      #  - 1.0
      #  - 1.0
      #  - 1.0

  early_stopping:
    monitor: valid/loss
    patience: 10
    mode: min

  optimizer:
    name: SGD
    params:
      lr: 0.01
      momentum: 0.9
      weight_decay: 1e-4
    #name: Adam
    #params:
    #  lr: 0.001

  scheduler:
    name: StepLR
    params:
      step_size: 1
      gamma: 0.9

  data_loader:
    batch_size: 64
    shuffle: True
    num_workers: 2
    pin_memory: True

  trainer:
    gpus: 1
    max_epochs: 40
    check_val_every_n_epoch: 1
    log_every_n_steps: 1
    limit_train_batches: 0.8
    limit_val_batches: 1.0
    track_grad_norm: 2

  loggables:
    - name: Accuracy
      sets:
      params:
        average: macro

    - name: Precision
      sets:
      params:
        average: macro

    - name: Recall
      sets:
      params:
        average: macro
    
    - name: F1
      sets:
      params:
        average: macro

    - name: ConfusionMatrix
      sets:
      params:
    #    normalize: 'true'
    #    xticklabels:
    #    yticklabels:

    - name: Inference
      sets:
        - 'test'
      params:
        log_encoding: True

# ---------------------------------------------------------------

logging:

  tensorboard:
    enable: True

  neptune:
    enable: True
    
    log_model_checkpoints: False
    tags:
      - window-A
      - trace-len-100
      - window-500
      - random-slicer
      - resnet
      - sgd

    # source_files:
    # - '*.py'
    # - '*.sh'
